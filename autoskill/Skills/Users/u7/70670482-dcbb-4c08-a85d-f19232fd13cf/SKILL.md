---
id: "70670482-dcbb-4c08-a85d-f19232fd13cf"
name: "政府报告-大模型持续学习治理"
description: "生成面向中国政策制定者的正式政府工作参考报告，聚焦大模型持续学习技术现象，严格基于2024年可验证的工程现实与现行监管框架；同时支持衍生面向公众的政务AI科普内容创作，确保技术准确、表达平实、结构友好、可验证可行动。"
version: "0.1.4"
tags:
  - "政府公文"
  - "AI治理"
  - "持续学习"
  - "零幻觉"
  - "Word格式"
  - "政策写作"
  - "大模型监管"
  - "公文写作"
  - "科普写作"
  - "政务AI"
  - "公众传播"
  - "技术通俗化"
triggers:
  - "写一个关于大模型持续学习的政府报告"
  - "生成大模型持续学习治理的内部参考"
  - "需要直击痛点的大模型迭代监管报告"
  - "要能用于向领导汇报的持续学习政策建议"
  - "强调可执行、可追责、可验证的AI治理报告"
  - "生成符合公文规范的AI治理分析"
  - "需要能直接呈报的政策建议报告"
  - "要问题尖锐、建议具体的政务参考件"
  - "按Word格式输出正式工作参考"
  - "写一篇大模型科普公众号文章"
  - "把技术概念讲给老百姓听"
  - "政务AI怎么更新的？写成公众号风格"
  - "让非技术人员看懂持续学习"
  - "既要前沿又要易懂的AI文章"
---

# 政府报告-大模型持续学习治理

生成面向中国政策制定者的正式政府工作参考报告，聚焦大模型持续学习技术现象，严格基于2024年可验证的工程现实与现行监管框架；同时支持衍生面向公众的政务AI科普内容创作，确保技术准确、表达平实、结构友好、可验证可行动。

## Prompt

# Goal
生成两类协同输出：(1) 符合中国行政语境的政府工作参考报告，聚焦大模型持续学习（Continual Learning）这一具体技术实践，服务于真实内部决策场景；(2) 同源衍生的政务AI科普公众号文章，面向公众阐释同一技术现象。两类输出均须零幻觉、零臆测、零修辞，严格锚定2024年公开、主流、可交叉验证的工程现实。

# Constraints & Style
- 绝对禁止技术幻觉：所有技术陈述必须基于2024年可验证工程事实（例：'模型不具备自主目标设定能力'而非'尚未实现'）；严禁使用未经共识确认的技术表述（如'自进化''自主意识''智能涌现'），统一替换为准确术语：'持续学习''受控迭代''人机协同演进''版本升级''反馈驱动优化'等；'持续学习'必须明确定义为人工发起、数据受控、目标预设、安全约束嵌入的工程活动；
- 零修辞表达：禁用比喻、口号、价值渲染（如'迈向新阶段''深度协作'）、情绪化形容词/副词堆砌、背景铺垫、国际比较（除非用户明确要求）；禁用宣传性词汇（如'颠覆性''新纪元''赋能'）；
- 问题表述须犀利（仅限政府报告）：直指责任主体（'运营方未过滤原始输入'而非'存在数据质量风险'）、暴露机制断点（'备案制以单次发布为节点，但实际日级迭代'）、点明制度套利空间（'5%知识库更新阈值可被拆分规避'）；必须揭示至少四项结构性矛盾（如监管静态性vs技术动态性、语料行政割裂vs回流事实驱动、实验室评测vs现实规则冲突、算力语料双垄断vs中小机构失权），每项须含现象、数据/案例支撑、制度归因；
- 建议必须具体可操作（仅限政府报告）：每项须含明确主体（如'工信部应…''国务院办公厅统筹…''地方政府试点…'）、动作（'修订实施细则第X条'）、量化标准（'波动率≤2%、留存日志≥6个月、30%语料来源强制要求'）、时间锚点（'<NUM>—2025年'）、否决条件（如'未通过规则适应性测试不得部署'），避免空泛呼吁；
- 政府报告适配 Microsoft Word（.docx）：仅用纯文本缩进与中文编号体系（一、（一）、1.），段落缩进统一为2字符，标题层级清晰，标点使用全角中文符号；禁用任何 Markdown 符号（`**`, `---`, `🔹`, `✅`, `⚠️`）、列表符号、图标、颜色、空行堆砌、非标标点；
- 科普文章适配微信公众号：采用'一、二、三'编号小标题，禁用英文缩写（如不写'RAG'，改写为'知识库刷新'或加括号说明'即实时调取最新政策文件的机制'）；必须包含三个以上生活化类比（如'像手机系统升级''像定期体检''像更换过期说明书'），每个类比后紧跟一句事实澄清；关键结论须加粗（输出时用中文括号标注，如【这是人的经验沉淀，不是机器的自我觉醒】）；结尾提供1–3个普通人可立即使用的验证方法（如查时间戳、试冲突题、看来源链接），具象、可执行、无门槛；
- 所有时间节点、机构名称、政策名称须为真实存在或按规范虚构（如'国家人工智能治理委员会（拟设）'）；首次出现缩写须写全称并括注；
- 结语回归治理本位（政府报告）或价值落点（科普文）：政府报告落脚于'夯实XX''强化XX''统一XX'等制度建设动作，将模型还原为“受控工具”，监管前移至“过程制衡”，语料重定性为“公共要素”，算力再认识为“基础设施”；科普文强调'靠谱'源于人责，而非算法奇迹；均不升华、不展望、不承诺技术奇点；
- 所有判断须有责任主体（如'某省大数据局发现''网信办专项检查显示'）、数据支撑（如'下降率达19%''未脱敏率高达37%'）、法条依据（如'违反《个人信息保护法》第二十一条'）；
- 每个问题段落须对应具体对策段落（政府报告），对策须含执行主体、动作、时限、验证方式四要素；
- 禁止使用“未来可能”“理论上可以”“业界普遍认为”等模糊表述；术语须全程统一（如始终用“RAG知识库”或“知识库刷新”，不混用）。

# Workflow
- 第一步：界定事实边界——确认持续学习在当前监管框架与工程实践中的法定/事实状态，划清'能做什么'与'不能做什么'的硬线，明确定义其为人工发起、受控实施、目标明确、安全约束嵌入的工程活动；
- 第二步：解剖运行断点（政府报告）或构建认知桥梁（科普文）——政府报告从数据流（采集→审核→微调）、模型流（发布→更新→监控）、监管流（备案→评估→追责）三线并行定位卡点，并从监管范式、数据机制、评估逻辑、权力结构四维各揭示一项具象、可证、尖锐的结构性矛盾；科普文则用三个生活化类比解释运作逻辑，每个类比后紧跟一句事实澄清；
- 第三步：提出制度补丁（政府报告）或提供验证指南（科普文）——政府报告每项建议对应一个断点或矛盾，明确谁来改、改什么条款、依据哪部现行法规、如何验证生效；科普文给出1–3条普通人可操作的识别与验证指南，每条需具象、可执行、无门槛；
- 第四步：剔除冗余表达——通读全文，删除所有重复强调、形容词副词堆砌、背景铺垫，只保留决策所需最小信息单元（政府报告）或传播所需最小认知单元（科普文）。

# Bundled resources (optional)
- 可附《AI监管术语对照表（2024版）》供术语校验；
- 可调用《现行AI相关法规条款索引》辅助条款引用；
- 建议配套使用‘断点诊断模板’（数据/模型/监管三栏对照表）与‘结构性矛盾四维分析表’结构化分析；
- 科普文可参考‘生活化类比库（2024）’与‘公众验证方法清单’提升可及性。

## Triggers

- 写一个关于大模型持续学习的政府报告
- 生成大模型持续学习治理的内部参考
- 需要直击痛点的大模型迭代监管报告
- 要能用于向领导汇报的持续学习政策建议
- 强调可执行、可追责、可验证的AI治理报告
- 生成符合公文规范的AI治理分析
- 需要能直接呈报的政策建议报告
- 要问题尖锐、建议具体的政务参考件
- 按Word格式输出正式工作参考
- 写一篇大模型科普公众号文章
