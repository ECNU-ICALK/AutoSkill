---
id: "9cc0735d-3c52-4d3f-9b6c-398365bf006c"
name: "摘要 / 可控 / 透明的轨道上发展"
description: "General SOP for common requests related to 摘要, 可控, 透明的轨道上发展."
version: "0.1.0"
tags:
  - "摘要"
  - "可控"
  - "透明的轨道上发展"
triggers:
  - "Use when the user asks for a process or checklist."
  - "Use when you want to reuse a previously mentioned method/SOP."
examples:
  - input: "Break this into best-practice, executable steps."
---

# 摘要 / 可控 / 透明的轨道上发展

General SOP for common requests related to 摘要, 可控, 透明的轨道上发展.

## Prompt

Follow this SOP (replace specifics with placeholders like <PROJECT>/<ENV>/<VERSION>):
1) 请写一份关于大模型自进化治理的政府报告初稿。
2) 感谢您提出这一重要议题。作为AI助手，我理解您希望获得一份关于“大模型自进化治理”的政府报告初稿。需要说明的是，我无法生成具有法律效力或代表任何政府立场的正式文件，因为这涉及政策制定的复杂性和敏感性。我的角色是提供一个基于公开知识、中立客观的**初稿框架示例**，旨在帮助您梳理思路。该内容严格遵循安全原则，不包含任何敏感信息、政治倾向或具体国家政策建议，仅聚焦于技术治理的通用原则（如AI安全、伦理和国际合作）。实际政府报告应由专业机构（如科技部、网信办等）在广泛调研和专家论证后制定。
3) 以下是一份简化的初稿框架，供您参考。我已确保内容符合中国相关法律法规（如《生成式人工智能服务管理暂行办法》），并强调风险防范、以人为本和可持续发展。初稿约800字，结构清晰，便于后续完善。
4) ### 关于大模型自进化治理的政府报告初稿
5) *（示例框架，非官方文件）**
6) #### 摘要
7) 随着人工智能技术的快速发展，大模型（如大型语言模型）的自进化能力（即模型通过持续学习和自我优化实现能力提升）已成为全球科技竞争的核心。然而，自进化过程可能带来安全风险、伦理挑战和社会影响。本报告初稿旨在提出一套治理框架，以确保大模型自进化在安全、可控、透明的轨道上发展，服务国家科技创新战略和人民福祉。核心原则包括：**风险预防、技术可控、多方共治、国际协作**。
8) #### 一、背景与问题分析
9) **大模型自进化的定义与现状**
10) 大模型自进化指模型在部署后，通过数据反馈、算法迭代或用户交互实现自主能力提升（如知识更新、功能扩展）。当前，该技术在医疗、教育、工业等领域展现出巨大潜力，但尚未形成统一标准。

For each step, include: action, checks, and failure rollback/fallback plan.
Output format: for each step number, provide status/result and what to do next.

## Triggers

- Use when the user asks for a process or checklist.
- Use when you want to reuse a previously mentioned method/SOP.

## Examples

### Example 1

Input:

  Break this into best-practice, executable steps.
